library(caTools)
library(dplyr)
library(ggplot2)
library(caret)
library(class)
library(corrplot)

#Now we import the data and store it to glass.
glass <- read.csv("glass.csv",
                  col.names=c("RI","Na","Mg","Al","Si","K","Ca","Ba","Fe","Type"))

# Here we are using scale() 
#to standardize the feature columns 
#of glassand assign it to a new variable. 
#Exclude the target column Type while scaling.

standard.features <- scale(glass[,1:9])

#Join the standardized data with the target column
data <- cbind(standard.features,glass[10])
#Check if there are any missing values to impute. 
anyNA(data)

# Looks like the data is free from NA's
head(data)

#plot explains the relation between 
#different features in glass dataset.
corrplot(cor(data))

#We use caTools() to split the data
#into train and test datasets 
#with a SplitRatio = 0.70
set.seed(101)

sample <- sample.split(data$Type,SplitRatio = 0.70)

train <- subset(data,sample==TRUE)

test <- subset(data,sample==FALSE)

#We use knn() to predict 
#our target variable Type of 
#the test dataset with k=1.
predicted.type <- knn(train[1:9],test[1:9],train$Type,k=1)
#Error in prediction
error <- mean(predicted.type!=test$Type)
#Confusion Matrix
confusionMatrix(factor(predicted.type),factor(test$Type))

#The above results reveal that 
#our model achieved an accuracy of 70.77 %. 
#Lets try different values of k 
#and assess our model.


predicted.type <- NULL
error.rate <- NULL

for (i in 1:10) {
  predicted.type <- knn(train[1:9],test[1:9],train$Type,k=i)
  error.rate[i] <- mean(predicted.type!=test$Type)
  
}

knn.error <- as.data.frame(cbind(k=1:10,error.type =error.rate))

#Choosing K Value by Visualization
#Lets plot error.type vs k using ggplot.
ggplot(knn.error,aes(k,error.type))+ 
  geom_point()+ 
  geom_line() + 
  scale_x_continuous(breaks=1:10)+ 
  theme_bw() +
  xlab("Value of K") +
  ylab('Error')

#plot reveals that error is lowest when k=3 
#and then jumps back high revealing that 
#k=3 is the optimum value. 
#Now lets build our model using k=3 
#and assess it.
predicted.type <- knn(train[1:9],test[1:9],train$Type,k=3)
#Error in prediction
error <- mean(predicted.type!=test$Type)
#Confusion Matrix
confusionMatrix(factor(predicted.type),factor(test$Type))

#The Above Model gave us an accuracy of 63.08 %.
